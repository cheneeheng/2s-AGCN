work_dir: ./data/data/ntu_result/xview/aagcn_v27_joint/220124163001_nopad_3ks_noaug_lowerlre5_adam
model_saved_name: ./data/data/ntu_result/xview/aagcn_v27_joint/220124163001_nopad_3ks_noaug_lowerlre5_adam/ntu_cv_aagcn_joint

phase: train
save_score: True

seed: 1
log_interval: 100 # iter
save_interval: 2 # iter
eval_interval: 5 # iter
print_log: true

# feeder
feeder: feeders.feeder.Feeder
num_worker: 32
train_feeder_args:
  data_path: ./data/data/ntu_nopad/xview/train_data_joint.npy
  label_path: ./data/data/ntu_nopad/xview/train_label.pkl
  debug: False
  random_choose: False
  random_shift: False
  random_move: False
  window_size: -1
  normalization: False
#  random_zaxis_flip: True
#  random_xaxis_shift: True
#  random_yaxis_shift: True

test_feeder_args:
  data_path: ./data/data/ntu_nopad/xview/val_data_joint.npy
  label_path: ./data/data/ntu_nopad/xview/val_label.pkl

# model
model: model.aagcn_v27.Model
model_args:
  num_class: 60
  num_point: 25
  num_person: 2
  num_subset: 3
  graph: graph.ntu_rgb_d.Graph
  graph_args:
    labeling_mode: "spatial"
  in_channels: 3
  drop_out: 0
  adaptive: True
  attention: True
  kernel_size: 3
  pad: False
  s_trans_cfg:
    attention_probs_dropout_prob: 0.2
    hidden_act: "gelu"
    hidden_dropout_prob: 0.2
    hidden_size: 16
    initializer_range: 0.02
    intermediate_size: 64
    max_position_embeddings: 51
    layer_norm_eps: 0.0000001
    num_attention_heads: 2
    num_hidden_layers: 3
    type_vocab_size: 0
    vocab_size: -1 # not used
    relative_attention: True
    position_buckets: 25 # the relative attn map span
    norm_rel_ebd: "layer_norm" # relative embedding norm
    share_att_key: False # whether to share the proj mat for pos and context attention ca√∂culation.  # noqa
    pos_att_type: "p2c | c2p" # p2p possible also
    # conv_kernel_size: 3 # whether to use conv in the first layer
    # conv_act: "gelu"
    max_relative_positions: -1 # if -1, uses max_position_embeddings
    position_biased_input: False # whether to add PE to input
    attention_head_size: 8
  pos_enc: True
  classifier_type: CLS
  model_layers: 101
#  gbn_split: 2
# weights: None

#optim
# device: [0, 1 ,2, 3]
device: [0, 1]
batch_size: 64
test_batch_size: 64

optimizer: Adam
nesterov: True
base_lr: 0.00001
step: [30, 40]
weight_decay: 0.0001

start_epoch: 0
num_epoch: 50
warm_up_epoch: 5

only_train_part: True
only_train_epoch: 5
